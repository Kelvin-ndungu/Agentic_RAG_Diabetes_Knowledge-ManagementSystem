{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title_01_data_extraction",
   "metadata": {},
   "source": [
    "# Data Extraction - PDF to Markdown\n",
    "\n",
    "**Notebook ID:** `01_data_extraction`\n",
    "**Description:** Convert PDF documents to Markdown format while preserving images and structure\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01_data_extraction_readme",
   "metadata": {},
   "source": [
    "## ðŸ“‹ How to Use This Notebook\n",
    "\n",
    "This notebook is **designed to work standalone** while maintaining state from previous notebooks.\n",
    "\n",
    "### âœ… Prerequisites Check\n",
    "- The first code cell checks for required files from previous notebooks\n",
    "- If files are missing, you'll see a warning with instructions\n",
    "- You can still run the notebook, but some cells may fail\n",
    "\n",
    "### ðŸš€ Starting from This Notebook\n",
    "If you want to start from this notebook (e.g., skip previous steps):\n",
    "\n",
    "1. **Ensure prerequisite files exist** in the expected locations\n",
    "2. **Update configuration** in the first code cell (PDF_NAME, paths, etc.)\n",
    "3. **Run all cells** - the notebook will load existing state or create new outputs\n",
    "\n",
    "### ðŸ’¾ State Management\n",
    "- Each notebook saves its state to `output/{notebook_name}_state.json`\n",
    "- State includes file paths, configuration, and intermediate results\n",
    "- Subsequent notebooks can load this state automatically\n",
    "\n",
    "### ðŸ“ File Locations\n",
    "- **Output files**: Saved to `output/` directory\n",
    "- **State files**: `output/{notebook_name}_state.json`\n",
    "- **Generated data**: Check the `PROJECT_STATE` dictionary after running cells\n",
    "\n",
    "### â­ï¸ Next Notebook\n",
    "After completing this notebook:\n",
    "- Output files are automatically saved\n",
    "- State is preserved for the next notebook\n",
    "- Run the next notebook in sequence, or jump to any later notebook\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01_data_extraction_dependency_check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL_ID: 01_data_extraction_dependency_check\n",
    "# ============================================================================\n",
    "# PREREQUISITE CHECK AND CONFIGURATION\n",
    "# ============================================================================\n",
    "# This cell checks for required files from previous notebooks and sets up\n",
    "# the environment. If you're starting from this notebook, make sure prerequisite\n",
    "# files exist, or run previous notebooks first.\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION: Set your project settings here\n",
    "# ============================================================================\n",
    "PDF_NAME = \"Kenya-National-Clinical-Guidelines-for-the-Management-of-Diabetes-2nd-Editiion-2018-1\"  # Change if using different PDF\n",
    "OUTPUT_DIR = Path(\"output\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Dictionary to store resolved file paths\n",
    "PROJECT_STATE = {\n",
    "    'pdf_name': PDF_NAME,\n",
    "    'output_dir': str(OUTPUT_DIR),\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# PREREQUISITE CHECK\n",
    "# ============================================================================\n",
    "missing_files = []\n",
    "found_files = []\n",
    "\n",
    "print(\"[OK] No prerequisites required for this notebook.\\n\")\n",
    "\n",
    "# ============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01_data_extraction_dependency_check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL_ID: 01_data_extraction_dependency_check\n",
    "# ============================================================================\n",
    "# PREREQUISITE CHECK AND CONFIGURATION\n",
    "# ============================================================================\n",
    "# This cell checks for required files from previous notebooks and sets up\n",
    "# the environment. If you're starting from this notebook, make sure prerequisite\n",
    "# files exist, or run previous notebooks first.\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION: Set your project settings here\n",
    "# ============================================================================\n",
    "PDF_NAME = \"Kenya-National-Clinical-Guidelines-for-the-Management-of-Diabetes-2nd-Editiion-2018-1\"  # Change if using different PDF\n",
    "OUTPUT_DIR = Path(\"output\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Dictionary to store resolved file paths\n",
    "PROJECT_STATE = {\n",
    "    'pdf_name': PDF_NAME,\n",
    "    'output_dir': str(OUTPUT_DIR),\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# PREREQUISITE CHECK\n",
    "# ============================================================================\n",
    "missing_files = []\n",
    "found_files = []\n",
    "\n",
    "print(\"[OK] No prerequisites required for this notebook.\\n\")\n",
    "\n",
    "# ============================================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01_data_extraction_ca42e518",
   "metadata": {},
   "source": [
    "## 1.1 PDF to Markdown Conversion with Images\n",
    "\n",
    "This section converts the PDF to Markdown format while preserving images in their correct positions using Docling and PyMuPDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01_data_extraction_26252ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL_ID: 01_data_extraction_26252ff6\n",
    "# Import required libraries\n",
    "import json  # For parsing Docling's JSON structure\n",
    "import os  # For operating system interface (though we use Path instead)\n",
    "from pathlib import Path  # For cross-platform path handling\n",
    "from docling.document_converter import DocumentConverter  # Docling: PDF to structured format converter\n",
    "import fitz  # PyMuPDF: For precise image extraction from PDF pages\n",
    "\n",
    "def extract_pdf_with_images(pdf_path, output_dir=\"output\"):\n",
    "    \"\"\"\n",
    "    Extract text and images from PDF using Docling + PyMuPDF.\n",
    "    Uses Docling's JSON structure to correctly place images in markdown.\n",
    "    \n",
    "    This function performs a 4-step process:\n",
    "    1. Convert PDF to Markdown and JSON using Docling\n",
    "    2. Analyze JSON structure to determine image order in document\n",
    "    3. Extract images precisely using PyMuPDF based on coordinates\n",
    "    4. Inject extracted images into markdown at correct positions\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to input PDF file\n",
    "        output_dir: Directory where output files will be saved\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with paths to output files and extraction statistics\n",
    "    \"\"\"\n",
    "    # ============================================================================\n",
    "    # SETUP: Create output directories\n",
    "    # ============================================================================\n",
    "    # Create main output directory if it doesn't exist (exist_ok=True prevents errors)\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Create subdirectory for extracted images\n",
    "    images_dir = output_path / \"images\"\n",
    "    images_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Extract PDF filename without extension (e.g., \"document.pdf\" -> \"document\")\n",
    "    pdf_name = Path(pdf_path).stem\n",
    "    \n",
    "    # ============================================================================\n",
    "    # STEP 1: Convert PDF with Docling\n",
    "    # ============================================================================\n",
    "    print(\"Converting PDF with Docling...\")\n",
    "    # Initialize Docling converter (handles OCR, layout analysis, structure detection)\n",
    "    converter = DocumentConverter()\n",
    "    # Convert PDF - this analyzes the document structure, extracts text, identifies images\n",
    "    result = converter.convert(pdf_path)\n",
    "    \n",
    "    # Export the converted document to Markdown format\n",
    "    # This gives us the text content with placeholders for images\n",
    "    markdown_content = result.document.export_to_markdown()\n",
    "    \n",
    "    # Save raw markdown (without images) to file\n",
    "    markdown_path = output_path / f\"{pdf_name}.md\"\n",
    "    with open(markdown_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(markdown_content)\n",
    "    print(f\"Markdown saved to: {markdown_path}\")\n",
    "    \n",
    "    # Export the full document structure as JSON\n",
    "    # The JSON contains detailed information: text blocks, images, tables, their positions, hierarchy\n",
    "    json_content = result.document.export_to_dict()\n",
    "    \n",
    "    # Save JSON structure for reference and analysis\n",
    "    json_path = output_path / f\"{pdf_name}.json\"\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(json_content, f, indent=2)\n",
    "    print(f\"JSON saved to: {json_path}\")\n",
    "    \n",
    "    # ============================================================================\n",
    "    # STEP 2: Parse JSON structure to determine image order\n",
    "    # ============================================================================\n",
    "    print(\"\\nAnalyzing document structure...\")\n",
    "    # The 'body' contains the main document content\n",
    "    body = json_content.get(\"body\", {})\n",
    "    # 'children' is an ordered list of all document elements (texts, images, tables)\n",
    "    # This order reflects the actual reading order in the PDF\n",
    "    children = body.get(\"children\", [])\n",
    "    \n",
    "    # Get all picture objects from the JSON\n",
    "    pictures = json_content.get(\"pictures\", [])\n",
    "    \n",
    "    # Create a mapping: picture self-reference -> picture index\n",
    "    # Each picture has a unique \"self_ref\" like \"#/pictures/0\", \"#/pictures/1\", etc.\n",
    "    # We need to map these references to their array indices\n",
    "    picture_ref_to_index = {}\n",
    "    for idx, picture in enumerate(pictures):\n",
    "        self_ref = picture.get(\"self_ref\", \"\")\n",
    "        if self_ref:\n",
    "            picture_ref_to_index[self_ref] = idx\n",
    "    \n",
    "    # Build ordered list of picture indices based on document reading order\n",
    "    # We iterate through body.children to find picture references in the order they appear\n",
    "    picture_order = []\n",
    "    for child in children:\n",
    "        ref = child.get(\"$ref\", \"\")  # Get the reference (e.g., \"#/pictures/5\")\n",
    "        if ref and \"#/pictures/\" in ref:  # Check if this is a picture reference\n",
    "            picture_idx = picture_ref_to_index.get(ref, None)\n",
    "            if picture_idx is not None:\n",
    "                picture_order.append(picture_idx)  # Add to ordered list\n",
    "    \n",
    "    print(f\"Found {len(pictures)} pictures in JSON\")\n",
    "    print(f\"Found {len(picture_order)} picture references in document structure\")\n",
    "    \n",
    "    # If no pictures found, return early with basic info\n",
    "    if len(pictures) == 0:\n",
    "        print(\"No pictures found in JSON. Check if PDF contains images.\")\n",
    "        return {\n",
    "            \"markdown_path\": str(markdown_path),\n",
    "            \"json_path\": str(json_path),\n",
    "            \"images_dir\": str(images_dir),\n",
    "            \"num_pictures\": 0,\n",
    "            \"num_images_extracted\": 0\n",
    "        }\n",
    "    \n",
    "    # ============================================================================\n",
    "    # STEP 3: Extract images using PyMuPDF (precise coordinate-based extraction)\n",
    "    # ============================================================================\n",
    "    print(\"\\nExtracting images with PyMuPDF...\")\n",
    "    # Open the original PDF with PyMuPDF for precise image extraction\n",
    "    pdf_doc = fitz.open(pdf_path)\n",
    "    \n",
    "    # Dictionary to store image information: picture_index -> {path, caption, page, etc.}\n",
    "    image_mapping = {}\n",
    "    \n",
    "    # Process pictures in the order they appear in the document\n",
    "    for picture_idx in picture_order:\n",
    "        if picture_idx >= len(pictures):\n",
    "            continue  # Skip if index is out of bounds\n",
    "            \n",
    "        picture = pictures[picture_idx]\n",
    "        try:\n",
    "            # Get provenance information - tells us where the image is located\n",
    "            prov = picture.get(\"prov\", [{}])[0]  # prov is a list, get first element\n",
    "            page_no = prov.get(\"page_no\", 1)  # Page number (1-indexed in Docling)\n",
    "            bbox = prov.get(\"bbox\", {})  # Bounding box: {l: left, t: top, r: right, b: bottom}\n",
    "            coord_origin = prov.get(\"coord_origin\", \"BOTTOMLEFT\")  # Coordinate system origin\n",
    "            \n",
    "            # Get the specific PDF page (PyMuPDF uses 0-indexed pages)\n",
    "            page = pdf_doc[page_no - 1]\n",
    "            page_height = page.rect.height  # Get page height for coordinate conversion\n",
    "            \n",
    "            # Convert coordinates from Docling's BOTTOMLEFT system to PyMuPDF's TOPLEFT system\n",
    "            # Docling: (0,0) is bottom-left, y increases upward\n",
    "            # PyMuPDF: (0,0) is top-left, y increases downward\n",
    "            if coord_origin == \"BOTTOMLEFT\":\n",
    "                x0 = bbox[\"l\"]  # Left coordinate (same in both systems)\n",
    "                y0 = page_height - bbox[\"t\"]  # Convert top: flip vertically\n",
    "                x1 = bbox[\"r\"]  # Right coordinate\n",
    "                y1 = page_height - bbox[\"b\"]  # Convert bottom: flip vertically\n",
    "            else:\n",
    "                # Already in TOPLEFT format\n",
    "                x0 = bbox[\"l\"]\n",
    "                y0 = bbox[\"t\"]\n",
    "                x1 = bbox[\"r\"]\n",
    "                y1 = bbox[\"b\"]\n",
    "            \n",
    "            # Create a rectangle defining the image area to extract\n",
    "            rect = fitz.Rect(x0, y0, x1, y1)\n",
    "            \n",
    "            # Render the page region as a pixmap (raster image)\n",
    "            # Matrix(2, 2) = 2x zoom for better image quality\n",
    "            # clip=rect extracts only the specified rectangle\n",
    "            mat = fitz.Matrix(2, 2)\n",
    "            pix = page.get_pixmap(matrix=mat, clip=rect)\n",
    "            \n",
    "            # Generate filename based on picture index and page number\n",
    "            img_filename = f\"picture_{picture_idx:03d}_page_{page_no}.png\"\n",
    "            img_path = images_dir / img_filename\n",
    "            pix.save(str(img_path))  # Save as PNG image\n",
    "            \n",
    "            # ====================================================================\n",
    "            # Extract caption for the image\n",
    "            # ====================================================================\n",
    "            caption = \"\"\n",
    "            \n",
    "            # Method 1: Check if picture has explicit captions in JSON\n",
    "            if picture.get(\"captions\"):\n",
    "                caption = picture[\"captions\"][0].get(\"text\", \"\").strip()\n",
    "            \n",
    "            # Method 2: Look for nearby text elements that might be captions\n",
    "            # (e.g., \"Figure 1: Description\")\n",
    "            if not caption:\n",
    "                # Find this picture's position in the document structure\n",
    "                for child_idx, child in enumerate(children):\n",
    "                    if child.get(\"$ref\") == picture.get(\"self_ref\"):\n",
    "                        # Look at nearby text elements (before and after the image)\n",
    "                        texts = json_content.get(\"texts\", [])\n",
    "                        # Check 1-2 positions ahead and behind\n",
    "                        for offset in [1, 2, -1, -2]:\n",
    "                            check_idx = child_idx + offset\n",
    "                            if 0 <= check_idx < len(children):\n",
    "                                text_ref = children[check_idx].get(\"$ref\", \"\")\n",
    "                                if \"#/texts/\" in text_ref:\n",
    "                                    text_idx = int(text_ref.split(\"/\")[-1])\n",
    "                                    if text_idx < len(texts):\n",
    "                                        text_content = texts[text_idx].get(\"text\", \"\").strip()\n",
    "                                        # Heuristic: captions usually start with \"Figure\" or are short descriptions\n",
    "                                        if text_content.startswith(\"Figure\") or (len(text_content) < 200 and len(text_content) > 5):\n",
    "                                            caption = text_content\n",
    "                                            break\n",
    "                        break\n",
    "            \n",
    "            # Fallback: use generic caption if none found\n",
    "            if not caption:\n",
    "                caption = f\"Figure {picture_idx + 1}\"\n",
    "            \n",
    "            # Store image information for later insertion into markdown\n",
    "            relative_path = f\"images/{img_filename}\"  # Relative path for markdown\n",
    "            image_mapping[picture_idx] = {\n",
    "                \"index\": picture_idx,\n",
    "                \"page\": page_no,\n",
    "                \"caption\": caption,\n",
    "                \"path\": relative_path\n",
    "            }\n",
    "            \n",
    "            print(f\"  [{len(image_mapping)}/{len(picture_order)}] Saved: {img_filename} (page {page_no}) - {caption[:60]}...\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error extracting picture {picture_idx}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    pdf_doc.close()  # Close the PDF file\n",
    "    \n",
    "    # ============================================================================\n",
    "    # STEP 4: Inject images into Markdown at correct positions\n",
    "    # ============================================================================\n",
    "    print(f\"\\nInjecting {len(image_mapping)} images into Markdown...\")\n",
    "    # Split markdown into lines for processing\n",
    "    markdown_lines = markdown_content.split(\"\\n\")\n",
    "    new_markdown_lines = []  # Will contain the final markdown with images\n",
    "    \n",
    "    # Counter to track which image we're inserting (maintains order)\n",
    "    image_insertion_counter = 0\n",
    "    \n",
    "    # Process each line of the markdown\n",
    "    for line_idx, line in enumerate(markdown_lines):\n",
    "        # Docling places \"<!-- image -->\" comments where images should appear\n",
    "        if \"<!-- image -->\" in line:\n",
    "            # Insert the next image in document order\n",
    "            if image_insertion_counter < len(picture_order):\n",
    "                picture_idx = picture_order[image_insertion_counter]\n",
    "                if picture_idx in image_mapping:\n",
    "                    img_info = image_mapping[picture_idx]\n",
    "                    # Replace placeholder with Markdown image syntax: ![alt text](path)\n",
    "                    img_tag = f\"![{img_info['caption']}]({img_info['path']})\"\n",
    "                    new_line = line.replace(\"<!-- image -->\", img_tag)\n",
    "                    new_markdown_lines.append(new_line)\n",
    "                    image_insertion_counter += 1\n",
    "                else:\n",
    "                    # Image extraction failed, keep placeholder but mark it\n",
    "                    new_markdown_lines.append(line.replace(\"<!-- image -->\", \"<!-- image (not extracted) -->\"))\n",
    "                    image_insertion_counter += 1\n",
    "            else:\n",
    "                # More placeholders than images (shouldn't happen, but handle gracefully)\n",
    "                new_markdown_lines.append(line)\n",
    "        else:\n",
    "            # Regular line, keep as-is\n",
    "            new_markdown_lines.append(line)\n",
    "    \n",
    "    # ============================================================================\n",
    "    # SAVE RESULTS\n",
    "    # ============================================================================\n",
    "    # Join lines back into full markdown document\n",
    "    enhanced_markdown = \"\\n\".join(new_markdown_lines)\n",
    "    enhanced_md_path = output_path / f\"{pdf_name}_with_images.md\"\n",
    "    with open(enhanced_md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(enhanced_markdown)\n",
    "    \n",
    "    print(f\"\\nâœ“ Enhanced Markdown saved to: {enhanced_md_path}\")\n",
    "    print(f\"âœ“ Total images extracted: {len(image_mapping)}\")\n",
    "    print(f\"âœ“ Images inserted: {image_insertion_counter}\")\n",
    "    print(f\"âœ“ Images directory: {images_dir}\")\n",
    "    \n",
    "    # Return summary dictionary for programmatic access to results\n",
    "    return {\n",
    "        \"markdown_path\": str(markdown_path),\n",
    "        \"enhanced_markdown_path\": str(enhanced_md_path),\n",
    "        \"json_path\": str(json_path),\n",
    "        \"images_dir\": str(images_dir),\n",
    "        \"num_pictures\": len(pictures),\n",
    "        \"num_images_extracted\": len(image_mapping),\n",
    "        \"num_images_inserted\": image_insertion_counter\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01_data_extraction_ce45d194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL_ID: 01_data_extraction_ce45d194\n",
    "# Separate execution cell - run the conversion\n",
    "pdf_file = \"Kenya-National-Clinical-Guidelines-for-the-Management-of-Diabetes-2nd-Editiion-2018-1.pdf\"\n",
    "results = extract_pdf_with_images(pdf_file, output_dir=\"output\")\n",
    "\n",
    "# Display results summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONVERSION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"âœ“ Markdown (raw): {results['markdown_path']}\")\n",
    "print(f\"âœ“ Markdown (with images): {results['enhanced_markdown_path']}\")\n",
    "print(f\"âœ“ JSON structure: {results['json_path']}\")\n",
    "print(f\"âœ“ Images directory: {results['images_dir']}\")\n",
    "print(f\"\\nðŸ“Š Statistics:\")\n",
    "print(f\"  â€¢ Total pictures found: {results['num_pictures']}\")\n",
    "print(f\"  â€¢ Images extracted: {results['num_images_extracted']}\")\n",
    "print(f\"  â€¢ Images inserted: {results['num_images_inserted']}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}